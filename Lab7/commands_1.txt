prathibha@ubuntu:~/hadoop/hadoop-3.3.0$ sbin/start-all.sh 
WARNING: Attempting to start all Apache Hadoop daemons as prathibha in 10 seconds.
WARNING: This is not a recommended production deployment configuration.
WARNING: Use CTRL-C to abort.
Starting namenodes on [localhost]
Starting datanodes
Starting secondary namenodes [ubuntu]
Starting resourcemanager
Starting nodemanagers
prathibha@ubuntu:~/hadoop/hadoop-3.3.0$ cd ..
prathibha@ubuntu:~/hadoop$ cd ..
prathibha@ubuntu:~$ start-master.sh 
starting org.apache.spark.deploy.master.Master, logging to /opt/spark/logs/spark-prathibha-org.apache.spark.deploy.master.Master-1-ubuntu.out
prathibha@ubuntu:~$ jps 
3059 ResourceManager
3189 NodeManager
2825 SecondaryNameNode
3354 Master
2509 NameNode
3581 Jps
2638 DataNode
prathibha@ubuntu:~$ hdfs dfs -mkdir /lab8
prathibha@ubuntu:~$ hdfs dfs -put ~/sample_temp.txt /lab8/input1.txt
prathibha@ubuntu:~$ hadoop jar ~/Desktop/AverageTemperature.jar AverageTemperature.lab8 /lab8/input1.txt /output1
Exception in thread "main" java.lang.ClassNotFoundException: AverageTemperature.lab8
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:348)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:316)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:236)
prathibha@ubuntu:~$ hadoop jar ~/Desktop/AverageTemperature.jar lab8.lab8 /lab8/input1.txt /output1
2021-05-10 05:54:11,629 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /127.0.0.1:8032
2021-05-10 05:54:13,657 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-05-10 05:54:13,723 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/prathibha/.staging/job_1620650938043_0001
2021-05-10 05:54:14,452 INFO input.FileInputFormat: Total input files to process : 1
2021-05-10 05:54:14,714 INFO mapreduce.JobSubmitter: number of splits:1
2021-05-10 05:54:15,796 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1620650938043_0001
2021-05-10 05:54:15,797 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-05-10 05:54:16,718 INFO conf.Configuration: resource-types.xml not found
2021-05-10 05:54:16,719 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-05-10 05:54:17,832 INFO impl.YarnClientImpl: Submitted application application_1620650938043_0001
2021-05-10 05:54:18,017 INFO mapreduce.Job: The url to track the job: http://ubuntu:8088/proxy/application_1620650938043_0001/
2021-05-10 05:54:18,018 INFO mapreduce.Job: Running job: job_1620650938043_0001
2021-05-10 05:54:53,415 INFO mapreduce.Job: Job job_1620650938043_0001 running in uber mode : false
2021-05-10 05:54:53,425 INFO mapreduce.Job:  map 0% reduce 0%
2021-05-10 05:55:16,239 INFO mapreduce.Job:  map 100% reduce 0%
2021-05-10 05:55:41,701 INFO mapreduce.Job:  map 100% reduce 100%
2021-05-10 05:55:46,853 INFO mapreduce.Job: Job job_1620650938043_0001 completed successfully
2021-05-10 05:55:47,143 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=61
		FILE: Number of bytes written=526877
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=635
		HDFS: Number of bytes written=15
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
		HDFS: Number of bytes read erasure-coded=0
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=18588
		Total time spent by all reduces in occupied slots (ms)=21914
		Total time spent by all map tasks (ms)=18588
		Total time spent by all reduce tasks (ms)=21914
		Total vcore-milliseconds taken by all map tasks=18588
		Total vcore-milliseconds taken by all reduce tasks=21914
		Total megabyte-milliseconds taken by all map tasks=19034112
		Total megabyte-milliseconds taken by all reduce tasks=22439936
	Map-Reduce Framework
		Map input records=5
		Map output records=5
		Map output bytes=45
		Map output materialized bytes=61
		Input split bytes=102
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=61
		Reduce input records=5
		Reduce output records=2
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=522
		CPU time spent (ms)=4130
		Physical memory (bytes) snapshot=453181440
		Virtual memory (bytes) snapshot=5062713344
		Total committed heap usage (bytes)=385351680
		Peak Map Physical memory (bytes)=270450688
		Peak Map Virtual memory (bytes)=2528141312
		Peak Reduce Physical memory (bytes)=182730752
		Peak Reduce Virtual memory (bytes)=2534572032
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=533
	File Output Format Counters 
		Bytes Written=15
prathibha@ubuntu:~$ hdfs dfs -cat /output1/*
1949	94
1950	3
prathibha@ubuntu:~$ 
